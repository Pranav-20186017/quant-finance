{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afece487-881e-4bb3-8247-6e27f47b7296",
   "metadata": {},
   "outputs": [],
   "source": [
    "import backtrader as bt\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "import tempfile\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b15d8a0-6c15-469d-9736-3d2c370cfc8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "read_csv() got an unexpected keyword argument 'date_format'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 77\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[0;32m     76\u001b[0m     file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./3csv/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 77\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mCustomCSVData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m     run_print(data)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\backtrader\\metabase.py:88\u001b[0m, in \u001b[0;36mMetaBase.__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m _obj, args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mdonew(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     87\u001b[0m _obj, args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mdopreinit(_obj, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 88\u001b[0m _obj, args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdoinit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m _obj, args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mdopostinit(_obj, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _obj\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\backtrader\\metabase.py:78\u001b[0m, in \u001b[0;36mMetaBase.doinit\u001b[1;34m(cls, _obj, *args, **kwargs)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdoinit\u001b[39m(\u001b[38;5;28mcls\u001b[39m, _obj, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 78\u001b[0m     \u001b[43m_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _obj, args, kwargs\n",
      "Cell \u001b[1;32mIn[4], line 15\u001b[0m, in \u001b[0;36mCustomCSVData.__init__\u001b[1;34m(self, file_type)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, file_type):\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_type \u001b[38;5;241m=\u001b[39m file_type\n\u001b[1;32m---> 15\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfile_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m002054.XSHE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfile_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m002054.XSHE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mopen\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclose\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m                            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhigh\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlow\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvolume\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m                            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmoney\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mavg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhigh_limit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m                            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlow_limit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpre_close\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpaused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m                            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfactor\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfile_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m002054.XSHE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfile_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m002054.XSHE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm-\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfile_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m002054.XSHE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm/\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     df\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     28\u001b[0m     temp_file \u001b[38;5;241m=\u001b[39m tempfile\u001b[38;5;241m.\u001b[39mNamedTemporaryFile(delete\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, suffix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: read_csv() got an unexpected keyword argument 'date_format'"
     ]
    }
   ],
   "source": [
    "class CustomCSVData(bt.feeds.GenericCSVData):\n",
    "    params = (\n",
    "        ('datetime', None),\n",
    "        ('open', -1),\n",
    "        ('high', -1),\n",
    "        ('low', -1),\n",
    "        ('close', -1),\n",
    "        ('volume', -1),\n",
    "        ('openinterest', -1),\n",
    "        ('dtformat', ('%Y-%m-%d')),\n",
    "    )\n",
    "    \n",
    "    def __init__(self, file_type):\n",
    "        self.file_type = file_type\n",
    "        df = pd.read_csv(self.p.dataname, parse_dates=['Date'], \n",
    "                         dayfirst=True if file_type != '002054.XSHE' else False,\n",
    "                         header=None if file_type == '002054.XSHE' else 0,\n",
    "                         names=['Date', 'open', 'close', \n",
    "                                'high', 'low', 'volume', \n",
    "                                'money', 'avg', 'high_limit', \n",
    "                                'low_limit', 'pre_close', 'paused', \n",
    "                                'factor'] if file_type == '002054.XSHE' else None,\n",
    "                         skiprows=1 if file_type == '002054.XSHE' else 0,\n",
    "                         date_format='%Y-%m-%d' if file_type == '002054.XSHE' else '%m/%d/%y')\n",
    "        df.sort_values(by='Date', inplace=True)\n",
    "\n",
    "\n",
    "        temp_file = tempfile.NamedTemporaryFile(delete=False, mode='w', suffix='.csv')\n",
    "        df.to_csv(temp_file.name, index=False)\n",
    "        self.p.dataname = temp_file.name\n",
    "        super().__init__()\n",
    "\n",
    "        # Define a dictionary to map file types to their parameters\n",
    "        file_type_params = {\n",
    "            '002054.XSHE': {'datetime': 0, 'open': 1, 'high': 2, 'low': 3, \n",
    "                            'close': 4, 'volume': 5},\n",
    "            'aapl': {'datetime': 0, 'open': 1, 'high': 2, 'low': 3, \n",
    "                     'close': 4, 'volume': 5, 'openinterest': -1},\n",
    "            'ERCOTDA_price': {'datetime': 0, 'hour_of_day': 1, 'close': 2}\n",
    "        }\n",
    "\n",
    "        # Apply the parameters based on file_type\n",
    "        params = file_type_params.get(file_type, {})\n",
    "        for param, value in params.items():\n",
    "            setattr(self.p, param, value)\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "    def stop(self):\n",
    "        os.remove(self.p.dataname)\n",
    "\n",
    "class PrintDataStrategy(bt.Strategy):\n",
    "    def __init__(self):\n",
    "        self.bar_counter = 0\n",
    "\n",
    "    def next(self):\n",
    "        num_bars_to_print = 5\n",
    "        if self.bar_counter < num_bars_to_print:\n",
    "            print(self.data.datetime.date(0), self.data.open[0], \n",
    "                  self.data.high[0], self.data.low[0], \n",
    "                  self.data.close[0], self.data.volume[0])\n",
    "            self.bar_counter += 1\n",
    "\n",
    "def run_print(data):\n",
    "    print(data.file_type)\n",
    "    print(\"Date: Open: High: Low: Close: Volume:\")\n",
    "    cerebro = bt.Cerebro()\n",
    "    cerebro.addstrategy(PrintDataStrategy)\n",
    "    cerebro.adddata(data)\n",
    "    cerebro.run()\n",
    "    print(\"...\\n\")\n",
    "\n",
    "# Run backtest for each dataset\n",
    "datasets = ['002054.XSHE', 'aapl', 'ERCOTDA_price']\n",
    "for dataset in datasets:\n",
    "    file_name = f'./3csv/{dataset}.csv'\n",
    "    data = CustomCSVData(dataname=file_name, file_type=dataset)\n",
    "    run_print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e087939-f597-4bc6-a20f-9401be163fa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7add98c8-dc48-4d99-8105-4f65b1d014bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058e4246-39bf-4b62-9332-844e728924e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ec23ed05-1a1d-4d04-89e4-0356e193e9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Logistic Regression: {'C': 10, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best Score for Logistic Regression: 0.6962901266701371\n",
      "Best Parameters for XGBoost: {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 50}\n",
      "Best Score for XGBoost: 0.6574492451847995\n",
      "Model: Logistic Regression\n",
      "Accuracy: 0.6920\n",
      "Precision: 0.6855\n",
      "Recall: 0.7340\n",
      "F1 Score: 0.7089\n",
      "ROC AUC Score: 0.6910\n",
      "\n",
      "Model: XGBoost\n",
      "Accuracy: 0.6514\n",
      "Precision: 0.6484\n",
      "Recall: 0.6943\n",
      "F1 Score: 0.6706\n",
      "ROC AUC Score: 0.6504\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "param_grid_lr = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.1, 1, 10],\n",
    "    'solver': ['liblinear'],\n",
    "    'max_iter': [1000]  \n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_lr = GridSearchCV(LogisticRegression(), param_grid_lr, cv=5, scoring='accuracy')\n",
    "grid_lr.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters for Logistic Regression:\", grid_lr.best_params_)\n",
    "print(\"Best Score for Logistic Regression:\", grid_lr.best_score_)\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [5, 50],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 10]\n",
    "}\n",
    "\n",
    "grid_xgb = GridSearchCV(XGBClassifier(use_label_encoder=False, eval_metric='logloss'), param_grid_xgb, cv=5, scoring='accuracy')\n",
    "grid_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best Parameters for XGBoost:\", grid_xgb.best_params_)\n",
    "print(\"Best Score for XGBoost:\", grid_xgb.best_score_)\n",
    "\n",
    "# Get the best estimators\n",
    "best_log_reg = grid_lr.best_estimator_\n",
    "best_xgb = grid_xgb.best_estimator_\n",
    "\n",
    "def evaluate_model(name, model, X_test, y_test):\n",
    "    predictions = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    precision = precision_score(y_test, predictions)\n",
    "    recall = recall_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions)\n",
    "    roc_auc = roc_auc_score(y_test, predictions)\n",
    "\n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"ROC AUC Score: {roc_auc:.4f}\\n\")\n",
    "\n",
    "# Evaluate Logistic Regression\n",
    "evaluate_model(\"Logistic Regression\", best_log_reg, X_test, y_test)\n",
    "# Evaluate XGBoost\n",
    "evaluate_model(\"XGBoost\", best_xgb, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "76c3b1b7-2138-4194-a7cf-9d42010e4ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<START> Brokerage account: $100000.00\n",
      "<FINISH> Brokerage account: $100191.98\n",
      "Trade Analysis Results:\n",
      "total: AutoOrderedDict([('total', 413), ('open', 0), ('closed', 413)])\n",
      "streak: AutoOrderedDict([('won', AutoOrderedDict([('current', 3), ('longest', 8)])), ('lost', AutoOrderedDict([('current', 0), ('longest', 9)]))])\n",
      "pnl: AutoOrderedDict([('gross', AutoOrderedDict([('total', 234.31801569461823), ('average', 0.5673559702048867)])), ('net', AutoOrderedDict([('total', 191.98233637440205), ('average', 0.4648482720929832)]))])\n",
      "won: AutoOrderedDict([('total', 163), ('pnl', AutoOrderedDict([('total', 524.2677467179299), ('average', 3.216366544281778), ('max', 123.30533331298828)]))])\n",
      "lost: AutoOrderedDict([('total', 250), ('pnl', AutoOrderedDict([('total', -332.2854103435277), ('average', -1.3291416413741108), ('max', -22.308037719726563)]))])\n",
      "long: AutoOrderedDict([('total', 413), ('pnl', AutoOrderedDict([('total', 191.98233637440205), ('average', 0.4648482720929832), ('won', AutoOrderedDict([('total', 524.2677467179299), ('average', 3.216366544281778), ('max', 123.30533331298828)])), ('lost', AutoOrderedDict([('total', -332.2854103435277), ('average', -1.3291416413741108), ('max', -22.308037719726563)]))])), ('won', 163), ('lost', 250)])\n",
      "short: AutoOrderedDict([('total', 0), ('pnl', AutoOrderedDict([('total', 0.0), ('average', 0.0), ('won', AutoOrderedDict([('total', 0.0), ('average', 0.0), ('max', 0.0)])), ('lost', AutoOrderedDict([('total', 0.0), ('average', 0.0), ('max', 0.0)]))])), ('won', 0), ('lost', 0)])\n",
      "len: AutoOrderedDict([('total', 1164), ('average', 2.818401937046005), ('max', 15), ('min', 1), ('won', AutoOrderedDict([('total', 708), ('average', 4.343558282208589), ('max', 15), ('min', 1)])), ('lost', AutoOrderedDict([('total', 456), ('average', 1.824), ('max', 9), ('min', 1)])), ('long', AutoOrderedDict([('total', 1164), ('average', 2.818401937046005), ('max', 15), ('min', 1), ('won', AutoOrderedDict([('total', 708), ('average', 4.343558282208589), ('max', 15), ('min', 1)])), ('lost', AutoOrderedDict([('total', 456), ('average', 1.824), ('max', 9), ('min', 1)]))])), ('short', AutoOrderedDict([('total', 0), ('average', 0.0), ('max', 0), ('min', 9223372036854775807), ('won', AutoOrderedDict([('total', 0), ('average', 0.0), ('max', 0), ('min', 9223372036854775807)])), ('lost', AutoOrderedDict([('total', 0), ('average', 0.0), ('max', 0), ('min', 9223372036854775807)]))]))])\n",
      "\n",
      "Sharpe Ratio:\n",
      "OrderedDict([('sharperatio', -28.029310195317887)])\n"
     ]
    }
   ],
   "source": [
    "# Backtrader strategy\n",
    "class MLStrategy(bt.Strategy):\n",
    "    def __init__(self):\n",
    "        self.ma_5 = bt.indicators.SimpleMovingAverage(self.data.close, period=5)\n",
    "        self.ma_10 = bt.indicators.SimpleMovingAverage(self.data.close, period=10)\n",
    "        self.ma_20 = bt.indicators.SimpleMovingAverage(self.data.close, period=20)\n",
    "\n",
    "        self.logistic_model = best_log_reg\n",
    "        self.xgboost_model = best_xgb\n",
    "\n",
    "    def next(self):\n",
    "        if len(self.data) >= 50:  # Adjust based on your longest indicator\n",
    "            # Convert to numpy array for TA-Lib calculations\n",
    "            close_array = np.array(self.data.close.get(size=50))\n",
    "            \n",
    "            # Calculate the indicators\n",
    "            rsi = talib.RSI(close_array, timeperiod=14)[-1]\n",
    "            macd, macdsignal, _ = talib.MACD(close_array, fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "\n",
    "            # Create a DataFrame for prediction with the same feature names\n",
    "            features = pd.DataFrame({\n",
    "                'Open': [self.data.open[0]],\n",
    "                'High': [self.data.high[0]],\n",
    "                'Low': [self.data.low[0]],\n",
    "                'Close': [self.data.close[0]],\n",
    "                'Volume': [self.data.volume[0]],\n",
    "                'MA5': [self.ma_5[0]],\n",
    "                'MA10': [self.ma_10[0]],\n",
    "                'MA20': [self.ma_20[0]],\n",
    "                'RSI': [rsi],\n",
    "                'MACD': [macd[-1]],\n",
    "                'MACD_signal': [macdsignal[-1]]\n",
    "            })\n",
    "\n",
    "            # features_scaled=features\n",
    "            features_scaled = pd.DataFrame(scaler.transform(features), columns=features.columns)\n",
    "           \n",
    "            logistic_pred = self.logistic_model.predict(features_scaled)[0]\n",
    "            xgboost_pred = self.xgboost_model.predict(features_scaled)[0]\n",
    "            final_prediction = round((logistic_pred + xgboost_pred) / 2)\n",
    "        \n",
    "            if final_prediction == 1 and not self.position:\n",
    "                self.order = self.buy()\n",
    "            elif final_prediction == 0 and self.position:\n",
    "                self.order = self.close()\n",
    "\n",
    "    def log(self, txt):\n",
    "        dt = self.datas[0].datetime.date(0)\n",
    "        print('%s, %s' % (dt.isoformat(), txt))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Create a cerebro instance, add our strategy, some starting cash at broker and a 0.1% broker commission\n",
    "    strat1 = bt.Cerebro()\n",
    "    strat1.addstrategy(MLStrategy)\n",
    "    strat1.broker.setcash(100000)\n",
    "    strat1.broker.setcommission(commission=0.001)\n",
    "    strat1.addanalyzer(bt.analyzers.TradeAnalyzer, _name=\"trade_analyzer\")\n",
    "    strat1.addanalyzer(bt.analyzers.SharpeRatio, _name='sharperatio', riskfreerate=0.01)\n",
    "\n",
    "    datafeed = bt.feeds.PandasData(dataname=yf.download(ticker, s, end_date, progress=False))\n",
    "\n",
    "    strat1.adddata(datafeed)\n",
    "\n",
    "    print('<START> Brokerage account: $%.2f' % strat1.broker.getvalue())\n",
    "    results = strat1.run()\n",
    "    print('<FINISH> Brokerage account: $%.2f' % strat1.broker.getvalue())\n",
    "    # strat1.plot(style='candlestick', loc='grey', grid=False)  # You can leave inside the parentheses empty\n",
    "    strategy = results[0]\n",
    "    # print(\"Trade Analysis:\", strategy.analyzers.trade_analyzer.get_analysis())\n",
    "    print(\"Trade Analysis Results:\")\n",
    "    trade_analysis = strategy.analyzers.trade_analyzer.get_analysis()\n",
    "    for key, value in trade_analysis.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    \n",
    "    print(\"\\nSharpe Ratio:\")\n",
    "    sharpe_ratio = strategy.analyzers.sharperatio.get_analysis()\n",
    "    print(sharpe_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fed4298b-3ec3-4a8b-8c4e-f76b6589ea61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Ticker  Accuracy\n",
      "357    NBL  0.698465\n",
      "23     EIX  0.698371\n",
      "154    MYL  0.696566\n",
      "107   HOLX  0.695263\n",
      "16     FLT  0.692866\n",
      "275    IVZ  0.692015\n",
      "65     NWS  0.691124\n",
      "319    RJF  0.690742\n",
      "1     TROW  0.689669\n",
      "62     PEG  0.687450\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826fead6-3ab2-471b-9ac2-18ecfaeebb0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7936ef31-a38b-4e2b-a12d-aa7052dd9ed7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696f09c6-f101-4350-a5eb-93f7b672222d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b8f029-83a9-451d-a439-91a76b7c464e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f67c084-e0c3-4128-8c1a-0f0f0ab50c75",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Lines_LineSeries_DataSeries_OHLC_OHLCDateTime_Abst' object has no attribute 'file_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 65\u001b[0m\n\u001b[0;32m     63\u001b[0m preprocessed_file \u001b[38;5;241m=\u001b[39m CustomCSVData\u001b[38;5;241m.\u001b[39mpreprocess_data(file_name, dataset)\n\u001b[0;32m     64\u001b[0m data \u001b[38;5;241m=\u001b[39m CustomCSVData(dataname\u001b[38;5;241m=\u001b[39mpreprocessed_file)\n\u001b[1;32m---> 65\u001b[0m \u001b[43mrun_print\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m os\u001b[38;5;241m.\u001b[39mremove(preprocessed_file)  \u001b[38;5;66;03m# Clean up temporary file\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 51\u001b[0m, in \u001b[0;36mrun_print\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_print\u001b[39m(data):\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_type\u001b[49m)\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate: Open: High: Low: Close: Volume:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     53\u001b[0m     cerebro \u001b[38;5;241m=\u001b[39m bt\u001b[38;5;241m.\u001b[39mCerebro()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\backtrader\\lineseries.py:461\u001b[0m, in \u001b[0;36mLineSeries.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;66;03m# to refer to line by name directly if the attribute was not found\u001b[39;00m\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;66;03m# in this object if we set an attribute in this object it will be\u001b[39;00m\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;66;03m# found before we end up here\u001b[39;00m\n\u001b[1;32m--> 461\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlines, name)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Lines_LineSeries_DataSeries_OHLC_OHLCDateTime_Abst' object has no attribute 'file_type'"
     ]
    }
   ],
   "source": [
    "import backtrader as bt\n",
    "import pandas as pd\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "class CustomCSVData(bt.feeds.GenericCSVData):\n",
    "    params = (\n",
    "        ('datetime', None),\n",
    "        ('open', -1),\n",
    "        ('high', -1),\n",
    "        ('low', -1),\n",
    "        ('close', -1),\n",
    "        ('volume', -1),\n",
    "        ('openinterest', -1),\n",
    "        ('dtformat', ('%Y-%m-%d')),\n",
    "    )\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    @classmethod\n",
    "    def preprocess_data(cls, file_name, file_type):\n",
    "        df = pd.read_csv(file_name, parse_dates=['Date'], \n",
    "                         dayfirst=True if file_type != '002054.XSHE' else False,\n",
    "                         header=None if file_type == '002054.XSHE' else 0,\n",
    "                         names=['Date', 'open', 'close', \n",
    "                                'high', 'low', 'volume', \n",
    "                                'money', 'avg', 'high_limit', \n",
    "                                'low_limit', 'pre_close', 'paused', \n",
    "                                'factor'] if file_type == '002054.XSHE' else None,\n",
    "                         skiprows=1 if file_type == '002054.XSHE' else 0)\n",
    "        df.sort_values(by='Date', inplace=True)\n",
    "\n",
    "        temp_file = tempfile.NamedTemporaryFile(delete=False, mode='w', suffix='.csv')\n",
    "        df.to_csv(temp_file.name, index=False)\n",
    "        return temp_file.name\n",
    "\n",
    "class PrintDataStrategy(bt.Strategy):\n",
    "    def __init__(self):\n",
    "        self.bar_counter = 0\n",
    "\n",
    "    def next(self):\n",
    "        num_bars_to_print = 5\n",
    "        if self.bar_counter < num_bars_to_print:\n",
    "            print(self.data.datetime.date(0), self.data.open[0], \n",
    "                  self.data.high[0], self.data.low[0], \n",
    "                  self.data.close[0], self.data.volume[0])\n",
    "            self.bar_counter += 1\n",
    "\n",
    "def run_print(data):\n",
    "    print(data.file_type)\n",
    "    print(\"Date: Open: High: Low: Close: Volume:\")\n",
    "    cerebro = bt.Cerebro()\n",
    "    cerebro.addstrategy(PrintDataStrategy)\n",
    "    cerebro.adddata(data)\n",
    "    cerebro.run()\n",
    "    print(\"...\\n\")\n",
    "\n",
    "# Run backtest for each dataset\n",
    "datasets = ['002054.XSHE', 'aapl', 'ERCOTDA_price']\n",
    "for dataset in datasets:\n",
    "    file_name = f'./3csv/{dataset}.csv'\n",
    "    preprocessed_file = CustomCSVData.preprocess_data(file_name, dataset)\n",
    "    data = CustomCSVData(dataname=preprocessed_file)\n",
    "    run_print(data)\n",
    "    os.remove(preprocessed_file)  # Clean up temporary file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7093f0-2ef1-48b5-9cd7-d00ba71b5336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394e2044-cc62-4547-835a-e0c6e418a216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242c7e94-1256-4ad2-9aae-f722bd74b584",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e034db8a-5381-45bc-879d-db52de77621f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: Open: High: Low: Close: Volume:\n",
      "2017-01-03 10.45 10.48 10.62 10.45 3669731.0\n",
      "2017-01-04 10.53 10.69 10.74 10.47 4380691.0\n",
      "2017-01-05 10.7 10.8 10.88 10.65 6346620.0\n",
      "2017-01-06 10.76 10.67 10.84 10.67 2941209.0\n",
      "2017-01-09 10.71 10.77 10.79 10.61 3270111.0\n",
      "...\n",
      "\n",
      "Date: Open: High: Low: Close: Volume:\n",
      "1999-01-04 0.376116007566452 0.3772319853305816 0.3571430146694183 0.3683040142059326 952884800.0\n",
      "1999-01-05 0.3744420111179352 0.3922989964485168 0.3705359995365143 0.3867189884185791 1410113600.0\n",
      "1999-01-06 0.3939729928970337 0.3939729928970337 0.3660709857940674 0.3727680146694183 1348569600.0\n",
      "1999-01-07 0.3772319853305816 0.4023439884185791 0.376116007566452 0.4017859995365143 1429019200.0\n",
      "1999-01-08 0.4157370030879974 0.4185270071029663 0.3928569853305816 0.4017859995365143 678832000.0\n",
      "...\n",
      "\n",
      "Date: Open: High: Low: Close: Volume:\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 67\u001b[0m\n\u001b[0;32m     65\u001b[0m preprocessed_file \u001b[38;5;241m=\u001b[39m CustomCSVData\u001b[38;5;241m.\u001b[39mpreprocess_data(file_name, dataset)\n\u001b[0;32m     66\u001b[0m data \u001b[38;5;241m=\u001b[39m CustomCSVData(dataname\u001b[38;5;241m=\u001b[39mpreprocessed_file)\n\u001b[1;32m---> 67\u001b[0m \u001b[43mrun_print\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m os\u001b[38;5;241m.\u001b[39mremove(preprocessed_file)  \u001b[38;5;66;03m# Clean up temporary file\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[10], line 58\u001b[0m, in \u001b[0;36mrun_print\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     56\u001b[0m cerebro\u001b[38;5;241m.\u001b[39maddstrategy(PrintDataStrategy)\n\u001b[0;32m     57\u001b[0m cerebro\u001b[38;5;241m.\u001b[39madddata(data)\n\u001b[1;32m---> 58\u001b[0m \u001b[43mcerebro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\backtrader\\cerebro.py:1132\u001b[0m, in \u001b[0;36mCerebro.run\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dooptimize \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp\u001b[38;5;241m.\u001b[39mmaxcpus \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1129\u001b[0m     \u001b[38;5;66;03m# If no optimmization is wished ... or 1 core is to be used\u001b[39;00m\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;66;03m# let's skip process \"spawning\"\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m iterstrat \u001b[38;5;129;01min\u001b[39;00m iterstrats:\n\u001b[1;32m-> 1132\u001b[0m         runstrat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunstrategies\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterstrat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1133\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunstrats\u001b[38;5;241m.\u001b[39mappend(runstrat)\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dooptimize:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\backtrader\\cerebro.py:1217\u001b[0m, in \u001b[0;36mCerebro.runstrategies\u001b[1;34m(self, iterstrat, predata)\u001b[0m\n\u001b[0;32m   1215\u001b[0m         data\u001b[38;5;241m.\u001b[39m_start()\n\u001b[0;32m   1216\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dopreload:\n\u001b[1;32m-> 1217\u001b[0m             \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m stratcls, sargs, skwargs \u001b[38;5;129;01min\u001b[39;00m iterstrat:\n\u001b[0;32m   1220\u001b[0m     sargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatas \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(sargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\backtrader\\feed.py:689\u001b[0m, in \u001b[0;36mCSVDataBase.preload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreload\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 689\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    690\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    692\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\backtrader\\feed.py:480\u001b[0m, in \u001b[0;36mAbstractDataBase.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fromstack(stash\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 480\u001b[0m     _loadret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    481\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _loadret:  \u001b[38;5;66;03m# no bar use force to make sure in exactbars\u001b[39;00m\n\u001b[0;32m    482\u001b[0m         \u001b[38;5;66;03m# the pointer is undone this covers especially (but not\u001b[39;00m\n\u001b[0;32m    483\u001b[0m         \u001b[38;5;66;03m# uniquely) the case in which the last bar has been seen\u001b[39;00m\n\u001b[0;32m    484\u001b[0m         \u001b[38;5;66;03m# and a backwards would ruin pointer accounting in the\u001b[39;00m\n\u001b[0;32m    485\u001b[0m         \u001b[38;5;66;03m# \"stop\" method of the strategy\u001b[39;00m\n\u001b[0;32m    486\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackwards(force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# undo data pointer\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\backtrader\\feed.py:711\u001b[0m, in \u001b[0;36mCSVDataBase._load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    709\u001b[0m line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39mrstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    710\u001b[0m linetokens \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseparator)\n\u001b[1;32m--> 711\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_loadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlinetokens\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\backtrader\\feeds\\csvgeneric.py:148\u001b[0m, in \u001b[0;36mGenericCSVData._loadline\u001b[1;34m(self, linetokens)\u001b[0m\n\u001b[0;32m    145\u001b[0m     csvfield \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp\u001b[38;5;241m.\u001b[39mnullvalue\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;66;03m# get it from the token\u001b[39;00m\n\u001b[1;32m--> 148\u001b[0m     csvfield \u001b[38;5;241m=\u001b[39m \u001b[43mlinetokens\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcsvidx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m csvfield \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;66;03m# if empty ... assign the \"nullvalue\"\u001b[39;00m\n\u001b[0;32m    152\u001b[0m     csvfield \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp\u001b[38;5;241m.\u001b[39mnullvalue\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import backtrader as bt\n",
    "import pandas as pd\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "class CustomCSVData(bt.feeds.GenericCSVData):\n",
    "    # Adjust the 'dtformat' parameter based on your CSV file's date format\n",
    "    params = (\n",
    "        ('datetime', 0),\n",
    "        ('open', 1),\n",
    "        ('high', 2),\n",
    "        ('low', 3),\n",
    "        ('close', 4),\n",
    "        ('volume', 5),\n",
    "        ('openinterest', -1),\n",
    "        ('dtformat', ('%Y-%m-%d')),  # Adjust this format if your CSV includes time\n",
    "    )\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    @classmethod\n",
    "    def preprocess_data(cls, file_name, file_type):\n",
    "        # Reading and preprocessing the CSV file\n",
    "        # Adjust this part based on the actual format of your CSV files\n",
    "        df = pd.read_csv(file_name, parse_dates=['Date'],\n",
    "                         dayfirst=True if file_type != '002054.XSHE' else False,\n",
    "                         header=None if file_type == '002054.XSHE' else 0,\n",
    "                         names=['Date', 'open', 'close', \n",
    "                                'high', 'low', 'volume', \n",
    "                                'money', 'avg', 'high_limit', \n",
    "                                'low_limit', 'pre_close', 'paused', \n",
    "                                'factor'] if file_type == '002054.XSHE' else None,\n",
    "                         skiprows=1 if file_type == '002054.XSHE' else 0)\n",
    "        df.sort_values(by='Date', inplace=True)\n",
    "\n",
    "        temp_file = tempfile.NamedTemporaryFile(delete=False, mode='w', suffix='.csv')\n",
    "        df.to_csv(temp_file.name, index=False)\n",
    "        return temp_file.name\n",
    "\n",
    "class PrintDataStrategy(bt.Strategy):\n",
    "    def __init__(self):\n",
    "        self.bar_counter = 0\n",
    "\n",
    "    def next(self):\n",
    "        num_bars_to_print = 5\n",
    "        if self.bar_counter < num_bars_to_print:\n",
    "            print(self.data.datetime.date(0), self.data.open[0], \n",
    "                  self.data.high[0], self.data.low[0], \n",
    "                  self.data.close[0], self.data.volume[0])\n",
    "            self.bar_counter += 1\n",
    "\n",
    "def run_print(data):\n",
    "    print(\"Date: Open: High: Low: Close: Volume:\")\n",
    "    cerebro = bt.Cerebro()\n",
    "    cerebro.addstrategy(PrintDataStrategy)\n",
    "    cerebro.adddata(data)\n",
    "    cerebro.run()\n",
    "    print(\"...\\n\")\n",
    "\n",
    "# Running backtest for each dataset\n",
    "datasets = ['002054.XSHE','aapl', 'ERCOTDA_price']\n",
    "for dataset in datasets:\n",
    "    file_name = f'./csv_data/{dataset}.csv'  # Ensure the file path is correct\n",
    "    preprocessed_file = CustomCSVData.preprocess_data(file_name, dataset)\n",
    "    data = CustomCSVData(dataname=preprocessed_file)\n",
    "    run_print(data)\n",
    "    os.remove(preprocessed_file)  # Clean up temporary file\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
